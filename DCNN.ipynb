{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"markdown","source":"This notebook uses different techniques to create models for classification of the images of letters in the dataset.\n\nFirstly we import the libraries we'll need."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"import numpy as np\nimport os\nimport sys\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-white')\nimport seaborn as sns\nfrom PIL import Image\n\nimport keras\nfrom keras.preprocessing.image import load_img\nfrom keras.models import Model, Sequential\nfrom keras.layers import Input, Dense, Dropout, Activation, BatchNormalization\nfrom keras.layers import Reshape, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.utils import to_categorical\nfrom keras.utils import np_utils\nfrom keras.regularizers import l1_l2\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\n%matplotlib inline\n%env JOBLIB_TEMP_FOLDER=/tmp","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"77d2f312278adb0ace9c40a52c16ceadc78f5cc6"},"cell_type":"markdown","source":"Select which data to use."},{"metadata":{"_kg_hide-output":false,"trusted":true,"collapsed":true,"_uuid":"5dc804c8f282dbac69446f4d84b94c989d702c90"},"cell_type":"code","source":"dataset = 'notMNIST_large'\nDATA_PATH = '../input/' + dataset + '/' + dataset\n\ntest = 'notMNIST_small'\nTEST_PATH = '../input/' + dataset + '/' + dataset","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ef07a200085684ca148f3b3a777a8e3ba3a1e468"},"cell_type":"markdown","source":"Check some data from the training dataset"},{"metadata":{"trusted":true,"_uuid":"f82d2d1e809136bddce06d7bc23fd09e32a110b6","collapsed":true},"cell_type":"code","source":"max_images = 100\ngrid_width = 10\ngrid_height = int(max_images / grid_width)\nfig, axs = plt.subplots(grid_height, grid_width, figsize=(grid_width, grid_height))\nclasses = os.listdir(DATA_PATH)\nfor j, cls in enumerate(classes):\n    figs = os.listdir(DATA_PATH + '/' + cls)\n    for i, fig in enumerate(figs[:grid_width]):\n        ax = axs[j, i]\n        ax.imshow(np.array(load_img(DATA_PATH + '/' + cls + '/' + fig)))\n        ax.set_yticklabels([])\n        ax.set_xticklabels([])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d663091049d096481d47c09a5493305c8f588edf"},"cell_type":"markdown","source":"Load images and make them ready for fitting a model."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"da1be1bb7c53c1c7c871aa947d7e26fa1c7775d2"},"cell_type":"code","source":"X = []\nlabels = []\n# for each folder (holding a different set of letters)\nfor directory in os.listdir(DATA_PATH):\n    # for each image\n    for image in os.listdir(DATA_PATH + '/' + directory):\n        # open image and load array data\n        try:\n            file_path = DATA_PATH + '/' + directory + '/' + image\n            img = Image.open(file_path)\n            img.load()\n            img_data = np.asarray(img, dtype=np.int16)\n            # add image to dataset\n            X.append(img_data)\n            # add label to labels\n            labels.append(directory)\n        except:\n            None # do nothing if couldn't load file\nN = len(X) # number of images\nimg_size = len(X[0]) # width of image\nX = np.asarray(X).reshape(N, img_size, img_size,1) # add our single channel for processing purposes\nlabels_cat = to_categorical(list(map(lambda x: ord(x)-ord('A'), labels)), 10) # convert to one-hot\nlabels = np.asarray(list(map(lambda x: ord(x)-ord('A'), labels)))\n\nX_test = []\ny_test = []\n# for each folder (holding a different set of letters)\nfor directory in os.listdir(TEST_PATH):\n    # for each image\n    for image in os.listdir(TEST_PATH + '/' + directory):\n        # open image and load array data\n        try:\n            file_path = DATA_PATH + '/' + directory + '/' + image\n            img = Image.open(file_path)\n            img.load()\n            img_data = np.asarray(img, dtype=np.int16)\n            # add image to dataset\n            X_test.append(img_data)\n            # add label to labels\n            y_test.append(directory)\n        except:\n            None # do nothing if couldn't load file\nN = len(X_test) # number of images\nimg_size = len(X_test[0]) # width of image\nX_test = np.asarray(X_test).reshape(N, img_size, img_size,1) # add our single channel for processing purposes\ny_test_cat = to_categorical(list(map(lambda x: ord(x)-ord('A'), y_test)), 10) # convert to one-hot\ny_test = np.asarray(list(map(lambda x: ord(x)-ord('A'), y_test)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7740588dc76628e0d58eb412795604527141e95f"},"cell_type":"markdown","source":"Check balance of classes."},{"metadata":{"trusted":true,"_uuid":"e0b0fb569d96152e7fad6dcfeb864310e461b216","collapsed":true},"cell_type":"code","source":"cls_s = np.sum(labels,axis=0)\n\nfig, ax = plt.subplots()\nplt.bar(np.arange(10), cls_s)\nplt.ylabel('No of pics')\nplt.xticks(np.arange(10), np.sort(classes))\nplt.title('Checking balance for data set..')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0502c16f8a89cc92d00f3e8c4b5454730b925db0"},"cell_type":"markdown","source":"Divide data into train/test datasets."},{"metadata":{"trusted":true,"_uuid":"74e62374fb904c7fda1528329dab6d6f02f4b981","collapsed":true},"cell_type":"code","source":"from sklearn.cross_validation import train_test_split\nX_train,X_valid,y_train,y_valid=train_test_split(X,labels,test_size=0.2)\nX_train_cat,X_valid_cat,y_train_cat,y_valid_cat=train_test_split(X,labels_cat,test_size=0.2)\n\nprint('Training:', X_train.shape, y_train.shape)\nprint('Validation:', X_valid.shape, y_valid.shape)\nprint('Test:', X_test.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0d9446bc6f30435fffb00158fab35f7471ca7fa7"},"cell_type":"markdown","source":"Sanity check of the final dataset."},{"metadata":{"trusted":true,"_uuid":"5f6a1940510822457680781886dfb509a2532c2a","collapsed":true},"cell_type":"code","source":"fig, axs = plt.subplots(grid_height, grid_width, figsize=(grid_width, grid_height))\nfor j in range(max_images):\n    ax = axs[int(j/grid_width), j%grid_width]\n    ax.imshow(X_train[j,:,:,0])\n    ax.set_yticklabels([])\n    ax.set_xticklabels([])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"94edfcc36047fd16ae80afad70168bb5f7a4ad21"},"cell_type":"markdown","source":"Let's start using TensorFlow, specifically I'll use Keras as its wrapper."},{"metadata":{"trusted":true,"_uuid":"6c995edcaac4e91e40169d85163f1ffe49c5bd48","collapsed":true},"cell_type":"code","source":"# helper functions\ndef plot_training_curves(history):\n    \"\"\"\n    Plot accuracy and loss curves for training and validation sets.\n    Args:\n        history: a Keras History.history dictionary\n    Returns:\n        mpl figure.\n    \"\"\"\n    fig, (ax_acc, ax_loss) = plt.subplots(1, 2, figsize=(8,2))\n    if 'acc' in history:\n        ax_acc.plot(history['acc'], label='acc')\n        if 'val_acc' in history:\n            ax_acc.plot(history['val_acc'], label='Val acc')\n        ax_acc.set_xlabel('epoch')\n        ax_acc.set_ylabel('accuracy')\n        ax_acc.legend(loc='upper left')\n        ax_acc.set_title('Accuracy')\n\n    ax_loss.plot(history['loss'], label='loss')\n    if 'val_loss' in history:\n        ax_loss.plot(history['val_loss'], label='Val loss')\n    ax_loss.set_xlabel('epoch')\n    ax_loss.set_ylabel('loss')\n    ax_loss.legend(loc='upper right')\n    ax_loss.set_title('Loss')\n\n    sns.despine(fig)\n    return\n\n# parameters\nbatch_size = 128\nnb_classes = 10\nnb_epoch = 200\ninput_dim = 784\nresolution = 28\nreg = l1_l2(l1=0, l2=0.02)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e782639612de4bd9551add7d0ffb8d7e36c43bec"},"cell_type":"markdown","source":"CNN structure."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"80676708e1fddb94a0fa957019e2302c2ed1261f"},"cell_type":"code","source":"# input image dimensions\nimg_rows, img_cols = 28, 28\n# number of convolutional filters to use\nnb_filters = 64\n# size of pooling area for max pooling\npool_size = [2, 2]\n# convolution kernel size\nkernel_size = [3, 3]\n\ninput_shape = [img_rows, img_cols, 1]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"57035a06cd296b7d1fcee18dde6dc4a3bb212dbe"},"cell_type":"markdown","source":"And then adding some more advance features to make our training process smarter."},{"metadata":{"trusted":true,"_uuid":"7856059cab75d564a22ec9170e5125e853aef424","scrolled":false,"collapsed":true},"cell_type":"code","source":"# define path to save model\nmodel_path = './cnn_notMNIST.h5'\n# prepare callbacks\ncallbacks = [\n    EarlyStopping(\n        monitor='val_acc', \n        patience=20,\n        mode='max',\n        verbose=1),\n    ModelCheckpoint(model_path,\n        monitor='val_acc', \n        save_best_only=True, \n        mode='max',\n        verbose=1),\n    ReduceLROnPlateau(\n        factor=0.1, \n        patience=5, \n        min_lr=0.00001, \n        verbose=1)\n]\n\n# model layers\ncnn_ad = Sequential()\ncnn_ad.add(Conv2D(nb_filters, kernel_size, padding='same', input_shape=input_shape))\ncnn_ad.add(Activation('relu'))\ncnn_ad.add(BatchNormalization())\ncnn_ad.add(Conv2D(nb_filters, kernel_size, padding='same'))\ncnn_ad.add(Activation('relu'))\ncnn_ad.add(BatchNormalization())\ncnn_ad.add(MaxPooling2D(pool_size=pool_size))\ncnn_ad.add(Dropout(0.25))\ncnn_ad.add(Flatten())\ncnn_ad.add(Dense(128, kernel_regularizer=reg))\ncnn_ad.add(Activation('relu'))\ncnn_ad.add(BatchNormalization())\ncnn_ad.add(Dropout(0.5))\ncnn_ad.add(Dense(nb_classes, kernel_regularizer=reg))\ncnn_ad.add(Activation('softmax'))\n\ncnn_ad.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n\nhistory = cnn_ad.fit(X_train_cat, y_train_cat,\n                 batch_size=batch_size, epochs=nb_epoch,\n                 verbose=0, validation_data=(X_valid_cat, y_valid_cat),\n                 shuffle=True, callbacks=callbacks)\nscore = cnn_ad.evaluate(X_test_cat, y_test_cat, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"06d96fe7ac4299a7c4389c7e964930f43f208bcc"},"cell_type":"markdown","source":"Let's check the accuracy on the test set."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"67792ee39215917f0ab07de4059658999730933d"},"cell_type":"code","source":"print('Test score:', score[0])\nprint('Test accuracy:', score[1])\n\nplot_training_curves(history.history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c15f64c9c38e3c8f63a3ae0c253e05dd2d796e4f"},"cell_type":"markdown","source":"So, with this notebook I've explored different architectures and strategies for classifying the notMNIST dataset, starting from the basics, till state-of-art architectures.\nThe best result is obtained by the CNN (accuracy ~95%) with further possible improvements related to hyper parameters tuning.\nIf you've any comment, question or advice, please do not hesitate to type it down in the comments."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}