{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"markdown","source":"This notebook uses different techniques to create models for classification of the images of letters in the dataset.\n\nFirstly we import the libraries we'll need."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"import numpy as np\nimport os\nimport sys\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-white')\nimport seaborn as sns\nfrom PIL import Image\n\nimport keras\nimport autokeras as ak\nfrom keras.preprocessing.image import load_img\nfrom keras.models import Model, Sequential\nfrom keras.layers import Input, Dense, Dropout, Activation, BatchNormalization\nfrom keras.layers import Reshape, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.utils import to_categorical\nfrom keras.utils import np_utils\nfrom keras.regularizers import l1_l2\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\n%matplotlib inline\n%env JOBLIB_TEMP_FOLDER=/tmp","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"77d2f312278adb0ace9c40a52c16ceadc78f5cc6"},"cell_type":"markdown","source":"Select which data to use."},{"metadata":{"_kg_hide-output":false,"trusted":true,"collapsed":true,"_uuid":"5dc804c8f282dbac69446f4d84b94c989d702c90"},"cell_type":"code","source":"dataset = 'notMNIST_small'\nDATA_PATH = '../input/' + dataset + '/' + dataset","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ef07a200085684ca148f3b3a777a8e3ba3a1e468"},"cell_type":"markdown","source":"Check some data from the training dataset"},{"metadata":{"trusted":true,"_uuid":"f82d2d1e809136bddce06d7bc23fd09e32a110b6","collapsed":true},"cell_type":"code","source":"max_images = 100\ngrid_width = 10\ngrid_height = int(max_images / grid_width)\nfig, axs = plt.subplots(grid_height, grid_width, figsize=(grid_width, grid_height))\nclasses = os.listdir(DATA_PATH)\nfor j, cls in enumerate(classes):\n    figs = os.listdir(DATA_PATH + '/' + cls)\n    for i, fig in enumerate(figs[:grid_width]):\n        ax = axs[j, i]\n        ax.imshow(np.array(load_img(DATA_PATH + '/' + cls + '/' + fig)))\n        ax.set_yticklabels([])\n        ax.set_xticklabels([])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d663091049d096481d47c09a5493305c8f588edf"},"cell_type":"markdown","source":"Load images and make them ready for fitting a model."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"da1be1bb7c53c1c7c871aa947d7e26fa1c7775d2"},"cell_type":"code","source":"X = []\nlabels = []\n# for each folder (holding a different set of letters)\nfor directory in os.listdir(DATA_PATH):\n    # for each image\n    for image in os.listdir(DATA_PATH + '/' + directory):\n        # open image and load array data\n        try:\n            file_path = DATA_PATH + '/' + directory + '/' + image\n            img = Image.open(file_path)\n            img.load()\n            img_data = np.asarray(img, dtype=np.int16)\n            # add image to dataset\n            X.append(img_data)\n            # add label to labels\n            labels.append(directory)\n        except:\n            None # do nothing if couldn't load file\nN = len(X) # number of images\nimg_size = len(X[0]) # width of image\nX = np.asarray(X).reshape(N, img_size, img_size,1) # add our single channel for processing purposes\nlabels_cat = to_categorical(list(map(lambda x: ord(x)-ord('A'), labels)), 10) # convert to one-hot\nlabels = np.asarray(list(map(lambda x: ord(x)-ord('A'), labels)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7740588dc76628e0d58eb412795604527141e95f"},"cell_type":"markdown","source":"Check balance of classes."},{"metadata":{"trusted":true,"_uuid":"e0b0fb569d96152e7fad6dcfeb864310e461b216","collapsed":true},"cell_type":"code","source":"cls_s = np.sum(labels,axis=0)\n\nfig, ax = plt.subplots()\nplt.bar(np.arange(10), cls_s)\nplt.ylabel('No of pics')\nplt.xticks(np.arange(10), np.sort(classes))\nplt.title('Checking balance for data set..')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0502c16f8a89cc92d00f3e8c4b5454730b925db0"},"cell_type":"markdown","source":"Divide data into train/test datasets."},{"metadata":{"trusted":true,"_uuid":"74e62374fb904c7fda1528329dab6d6f02f4b981","collapsed":true},"cell_type":"code","source":"from sklearn.cross_validation import train_test_split\nX_train,X_valid,y_train,y_valid=train_test_split(X,labels,test_size=0.2)\nX_train_cat,X_valid_cat,y_train_cat,y_valid_cat=train_test_split(X,labels_cat,test_size=0.2)\n\nprint('Training:', X_train.shape, y_train.shape)\nprint('Validation:', X_valid.shape, y_valid.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"50291ff2bfebe0de792e46c2fb0aa780d3e0853c"},"cell_type":"markdown","source":"Let's shuffle the data for a better conditioning of the sets. (useless?)"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c96312c7009b13545b2982e6027d5a60bc7421f2"},"cell_type":"code","source":"# def randomize(dataset, labels):\n#   permutation = np.random.permutation(labels.shape[0])\n#   shuffled_dataset = dataset[permutation,:,:]\n#   shuffled_labels = labels[permutation]\n#   return shuffled_dataset, shuffled_labels\n#   \n# X_train, y_train = randomize(X_train, y_train)\n# X_test, y_test = randomize(X_test, y_test)\n# X_train_cat, y_train_cat = randomize(X_train_cat, y_train_cat)\n# X_test_cat, y_test_cat = randomize(X_test_cat, y_test_cat)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0d9446bc6f30435fffb00158fab35f7471ca7fa7"},"cell_type":"markdown","source":"Sanity check of the final dataset."},{"metadata":{"trusted":true,"_uuid":"5f6a1940510822457680781886dfb509a2532c2a","collapsed":true},"cell_type":"code","source":"fig, axs = plt.subplots(grid_height, grid_width, figsize=(grid_width, grid_height))\nfor j in range(max_images):\n    ax = axs[int(j/grid_width), j%grid_width]\n    ax.imshow(X_train[j,:,:,0])\n    ax.set_yticklabels([])\n    ax.set_xticklabels([])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9792618950397e46e46ca48e525fa2669d8a005d"},"cell_type":"markdown","source":"Prepare the data."},{"metadata":{"trusted":true,"_uuid":"cfae991abc35ab4b84a5c1123dcbf52e277246ee","collapsed":true},"cell_type":"code","source":"samples, width, height = np.squeeze(X_train).shape\nX_train_lr = np.reshape(X_train,(samples,width*height))\ny_train_lr = y_train\n\nsamples, width, height = np.squeeze(X_valid).shape\nX_valid_lr = np.reshape(X_valid,(samples,width*height))\ny_valid_lr = y_valid","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8bc319cc6d19ed227ea93fbd2b1eee08e3681124"},"cell_type":"markdown","source":"Let's see what AutoKeras produces:"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"81c7979a8818de18cc5f0390c66ae8b81b2c779d"},"cell_type":"code","source":"clf = ak.ImageClassifier(verbose=1,augment=1)\nclf.fit(X_train_cat, y_train_cat)\nclf.final_fit(X_train_cat, y_train_cat, X_test_cat, y_test_cat, retrain=True)\nresults = clf.predict(X_test_cat)\n\nscore = clf.evaluate(X_test_cat, y_test_cat, verbose=0)\n\nprint('Test score:', score[0])\nprint('Test accuracy:', score[1])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"83b747f426d4c87730c697ec50948014ea883dfb"},"cell_type":"markdown","source":"So, the architecture found by this autoML algorithm is:"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2ea246211fac491ad281321b85591d0d0d4de5ab"},"cell_type":"code","source":"... to test ...","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}